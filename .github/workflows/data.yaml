name: "Data Pipeline"

on:
  workflow_dispatch:  # This event triggers the workflow manually

jobs:
  train-model:
    runs-on: self-hosted # The runner environment (self-hosted in this case)

    steps:
      - name: Checkout the code from the branch
        uses: actions/checkout@v4

      - name: Set up Python 3.9
        uses: actions/setup-python@v2
        with:
          python-version: 3.9

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run unit tests
        run: pytest tests/data -v

      - name: Download sample data
        run: python download_data.py --source-path "s3://my-bucket/data" --destination-dir ${{ github.workspace }}/data --sample
        timeout-minutes: 10

      # - name: Pre-process sample data
      #   run: preprocess.py --input-dir ${{ github.workspace }}/data --output-dir ${{ github.workspace }}/processed_data --sample
      #   timeout-minutes: 10

      # - name: Download full data
      #   run: python download_data.py --source-path "s3://my-bucket/data" --destination-dir ${{ github.workspace }}/data

      # - name: Pre-process full data
      #   run: preprocess.py --input-dir ${{ github.workspace }}/data --output-dir ${{ github.workspace }}/processed_data

      # - name: Publish dataset statistics/alerts
      #   run: python publish_dataset_stats.py --input-dir ${{ github.workspace }}/processed_data --output-dir ${{ github.workspace }}/alerts

      
  
  print-metrics:
    runs-on: ubuntu-latest
    needs: [train-model]
    steps:
      - name: Download metrics
        uses: actions/download-artifact@v3
        with:
          name: model-metrics
          path: metrics

      - name: Print metrics
        run: cat metrics/metrics.json